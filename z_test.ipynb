{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg19, vgg16_bn\n",
    "\n",
    "import model\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = dataloader.imagenet_loader(bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = vgg16_bn(pretrained=True)\n",
    "model = model.Googlenet_for_CAM()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(epoch):\n",
    "    top1_accuracy = 0.\n",
    "    top5_accuracy = 0.\n",
    "    loss = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for idx, (inputs, targets) in tqdm_notebook(enumerate(valid_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss += criterion(outputs, targets).detach().cpu().item()\n",
    "\n",
    "        topk = outputs.topk(5,dim=1)[1]\n",
    "        top1_accuracy += topk[:,0].eq(targets).sum().cpu().item()\n",
    "        top5_accuracy += topk.eq(torch.stack([targets]*5,dim=1)).max(1)[0].sum().cpu().item()\n",
    "    \n",
    "    top1_accuracy /= len(valid_loader.dataset)\n",
    "    top5_accuracy /= len(valid_loader.dataset)\n",
    "    loss /= len(valid_loader.dataset)\n",
    "\n",
    "    print('Classification')\n",
    "    print(f'===> Test Loss: {loss:.4f}, Top1-Acc: {top1_accuracy*100:.4f}, Top5-Acc: {top5_accuracy*100:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy(0) \n",
    "# vgg19 ===> Test Loss: 0.0349, Top1-Acc: 72.3760, Top5-Acc: 90.8760\n",
    "# vgg16_bn ===> Test Loss: 0.0333, Top1-Acc: 73.3600, Top5-Acc: 91.5160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification & Localization (top-1 Loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16, vgg16_bn\n",
    "\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from os.path import join,expanduser\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cam import CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = dataloader.imagenet_loader(bs=10)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# model = vgg16_bn(pretrained=True)\n",
    "# model = model.to(device)\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = CAM('googlenet')\n",
    "data_dict = map.valid_dataset.data_dict\n",
    "input_files = map.valid_dataset.img_files\n",
    "img_dir = map.valid_dataset.img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = map.model\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_dict = {}\n",
    "with open('runs/googlenet/0.2_0.4/bbox.csv','r') as cf:\n",
    "    for row in csv.reader(cf):\n",
    "        k,v = row\n",
    "        bboxes_dict[k] = eval(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bboxes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc01df37a88548da85362b6c717de5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification & Localization\n",
      "===> Top1-Loc: 0.47602, Top1-Acc: 0.7232, GTKnown: 0.61674\n",
      "===> Top5-Loc: 0.5805, Top5-Acc: 0.90908\n"
     ]
    }
   ],
   "source": [
    "### def test_accuracy(epoch):\n",
    "\n",
    "top1_acc_cls = 0.\n",
    "top5_acc_cls = 0.\n",
    "gtknown_acc_loc = 0.\n",
    "top1_acc_loc = 0.\n",
    "top5_acc_loc = 0.\n",
    "loss = 0.\n",
    "\n",
    "count = 0\n",
    "model.eval()\n",
    "for idx, (inputs, targets) in tqdm_notebook(enumerate(valid_loader)):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    loss += criterion(outputs, targets).detach().cpu().item()\n",
    "    \n",
    "    topk = outputs.topk(5,dim=1)[1]\n",
    "    top1_acc_clss = topk[:,0].eq(targets).cpu().numpy()\n",
    "    top5_acc_clss = topk.eq(torch.stack([targets]*5,dim=1)).max(1)[0].cpu().numpy()\n",
    "    \n",
    "    gtknown_acc_locs = []\n",
    "    for data_idx in range(idx*10,(idx+1)*10):\n",
    "        count += 1\n",
    "    \n",
    "        # get true bbox\n",
    "        input_file = input_files[data_idx]\n",
    "        img_origin = Image.open(join(img_dir, input_file)).convert('RGB')\n",
    "        bboxes_true = data_dict[input_file][1]\n",
    "        bboxes_true = util.bboxes_resize(img_origin, bboxes_true, size=224)\n",
    "\n",
    "        # get proposed bbox\n",
    "        bbox_propose = bboxes_dict[input_file]\n",
    "\n",
    "        # get iou\n",
    "        iou_propose = []\n",
    "        for bbox_true in bboxes_true:\n",
    "            iou_propose.append(util.get_iou(bbox_true, bbox_propose))\n",
    "        iou_propose = max(np.array(iou_propose) >= 0.5).astype(np.int)\n",
    "        gtknown_acc_locs.append(iou_propose)\n",
    "        \n",
    "    top1_acc_locs = np.logical_and(top1_acc_clss, gtknown_acc_locs)\n",
    "    top5_acc_locs = np.logical_and(top5_acc_clss, gtknown_acc_locs)\n",
    "    \n",
    "    top1_acc_cls += top1_acc_clss.sum()\n",
    "    top5_acc_cls += top5_acc_clss.sum()\n",
    "    gtknown_acc_loc += np.array(gtknown_acc_locs).sum()\n",
    "    top1_acc_loc += top1_acc_locs.sum()\n",
    "    top5_acc_loc += top5_acc_locs.sum()\n",
    "    \n",
    "#     if idx == 999:\n",
    "#         break\n",
    "\n",
    "top1_acc_cls /= count\n",
    "top5_acc_cls /= count\n",
    "gtknown_acc_loc /= count\n",
    "top1_acc_loc /= count\n",
    "top5_acc_loc /= count\n",
    "print('Classification & Localization')\n",
    "print(f'===> Top1-Loc: {top1_acc_loc}, Top1-Acc: {top1_acc_cls}, GTKnown: {gtknown_acc_loc}')\n",
    "print(f'===> Top5-Loc: {top5_acc_loc}, Top5-Acc: {top5_acc_cls}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vgg16_bn \n",
    "vanilla ===> Top1-Loc: 0.44906, Top1-Acc: 0.7336, GTKnown: 0.57684, Top5-Loc: 0.54378, Top5-Acc: 0.91516 <br>\n",
    "ours ===> Top1-Loc: 0.47832, Top1-Acc: 0.7336, GTKnown: 0.61506, Top5-Loc: 0.5803, Top5-Acc: 0.91516\n",
    "\n",
    "#### GoogLeNet\n",
    "vanilla ===> Top1-Loc: 0.45264, Top1-Acc: 0.7232, GTKnown: 0.5849, Top5-Loc: 0.55128, Top5-Acc: 0.90908 <br>\n",
    "ours ===> Top1-Loc: 0.47602, Top1-Acc: 0.7232, GTKnown: 0.61674, Top5-Loc: 0.5805, Top5-Acc: 0.90908\n",
    "\n",
    "#### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join('aa','bb','','cc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'\n",
    "\n",
    "from os.path import join, expanduser\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from cam import CAM\n",
    "import util\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = CAM('vgg')\n",
    "\n",
    "class_dict = dataloader.get_class_dict(join(expanduser('~'),'data','imagenet'))[0]\n",
    "data_dict = map.valid_dataset.data_dict\n",
    "input_files = map.valid_dataset.img_files\n",
    "img_dir = map.valid_dataset.img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_plt(data_idx, th1=0.2, th2=10, mc=15):\n",
    "    # get true bbox\n",
    "    input_file = input_files[data_idx]\n",
    "    img_origin = Image.open(join(img_dir, input_file)).convert('RGB')\n",
    "    bboxes_true = data_dict[input_file][1]\n",
    "    bboxes_true = util.bboxes_resize(img_origin, bboxes_true, size=224)\n",
    "    \n",
    "    # get input, target, and topk\n",
    "    input, target = map.get_item(data_idx)\n",
    "    target = target.cpu().item()\n",
    "\n",
    "    topk_idxs = map.topk(input)\n",
    "    top1_correct = target in topk_idxs[:1]\n",
    "    top5_correct = target in topk_idxs[:5]\n",
    "    \n",
    "    att_idx = target\n",
    "    \n",
    "    # origin\n",
    "    img, heatmap_origin, boolmap, boolmap_biggest, \\\n",
    "    bbox_pred = map.get_values(data_idx,att_idx, th1, phase='test')\n",
    "    \n",
    "    # propose\n",
    "    _, heatmap_mean, heatmap_std, boolmap_propose, boolmap_biggest_propose, \\\n",
    "    bbox_propose = map.get_values(data_idx, att_idx, th1, th2, mc, phase='train')\n",
    "    heatmap_std_max = heatmap_std.max()\n",
    "    \n",
    "    # save the plot\n",
    "    fig, ax = plt.subplots(2,5,figsize=(20.5,8))\n",
    "    \n",
    "    ax[0,0].imshow(img)\n",
    "    ax[0,0].set_title('input', fontsize=15)\n",
    "    ax[0,0].axis('off')\n",
    "\n",
    "    ax[0,1].imshow(heatmap_origin, cmap='gray')\n",
    "    ax[0,1].set_title('$L^{grad}$', fontsize=15)\n",
    "    ax[0,1].axis('off')\n",
    "\n",
    "    ax[0,2].imshow(img)\n",
    "    ax[0,2].imshow(heatmap_origin, alpha=0.5, cmap='jet')\n",
    "    ax[0,2].set_title('GradCAM', fontsize=15)\n",
    "    ax[0,2].axis('off')\n",
    "\n",
    "#     ax[0,3].imshow(Image.fromarray((boolmap*255).astype(np.uint8)), cmap='gray')\n",
    "#     ax[0,3].set_title('boolean map')\n",
    "#     ax[0,3].axis('off')\n",
    "\n",
    "    ax[0,3].imshow(Image.fromarray((boolmap_biggest*255).astype(np.uint8)), cmap='gray')\n",
    "    ax[0,3].set_title('boolean map', fontsize=15)\n",
    "    ax[0,3].axis('off')\n",
    "\n",
    "    ax[0,4].imshow(img)\n",
    "    for bbox_true in bboxes_true:\n",
    "        rect_true = patches.Rectangle((bbox_true[0],bbox_true[1]),bbox_true[2],bbox_true[3],\n",
    "                                      linewidth=3,edgecolor='#00d700',facecolor='none')\n",
    "        ax[0,4].add_patch(rect_true)\n",
    "    rect_pred = patches.Rectangle((bbox_pred[0],bbox_pred[1]),bbox_pred[2],bbox_pred[3],\n",
    "                                  linewidth=3,edgecolor='r',facecolor='none')\n",
    "    ax[0,4].add_patch(rect_pred)\n",
    "    ax[0,4].set_title('bounding box', fontsize=15)\n",
    "    ax[0,4].axis('off')\n",
    "\n",
    "\n",
    "    ax[1,0].imshow(heatmap_mean, cmap='gray')\n",
    "    ax[1,0].set_title('$L^{mean}$', fontsize=15)\n",
    "    ax[1,0].axis('off')\n",
    "\n",
    "    ax[1,1].imshow(heatmap_std, cmap='gray')\n",
    "    ax[1,1].set_title(r'$L^{std}$', fontsize=15)\n",
    "    ax[1,1].axis('off')\n",
    "\n",
    "    im1 = ax[1,2].imshow(heatmap_mean, cmap='Reds', label='mean')\n",
    "    im2 = ax[1,2].imshow(heatmap_std, cmap='Blues', label='std', alpha=0.5)\n",
    "    ax[1,2].set_title('DropoutCAM', fontsize=15)\n",
    "    ax[1,2].axis('off')\n",
    "    patch = [patches.Patch(color=im1.cmap(150), label='mean'), \n",
    "             patches.Patch(color=im2.cmap(150), label='std')]\n",
    "    ax[1,2].legend(handles=patch, loc='best')\n",
    "\n",
    "#     ax[1,3].imshow(Image.fromarray((boolmap_propose*255).astype(np.uint8)), cmap='gray')\n",
    "#     ax[1,3].set_title('boolean map')\n",
    "#     ax[1,3].axis('off')\n",
    "\n",
    "    ax[1,3].imshow(Image.fromarray((boolmap_biggest_propose*255).astype(np.uint8)), cmap='gray')\n",
    "    ax[1,3].set_title('boolean map', fontsize=15)\n",
    "    ax[1,3].axis('off')\n",
    "\n",
    "    ax[1,4].imshow(img)\n",
    "    for bbox_true in bboxes_true:\n",
    "        rect_true = patches.Rectangle((bbox_true[0],bbox_true[1]),bbox_true[2],bbox_true[3],\n",
    "                                      linewidth=3,edgecolor='#00d700',facecolor='none')\n",
    "        ax[1,4].add_patch(rect_true)\n",
    "    rect_pred = patches.Rectangle((bbox_propose[0],bbox_propose[1]),bbox_propose[2],bbox_propose[3],\n",
    "                                  linewidth=3,edgecolor='r',facecolor='none')\n",
    "    ax[1,4].add_patch(rect_pred)\n",
    "    ax[1,4].set_title('bounding box', fontsize=15)\n",
    "    ax[1,4].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "#     plt.show()\n",
    "    plt.savefig(join('imgs',f'{data_idx:05d}.png'))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data_idx in tqdm_notebook(range(1000)):\n",
    "#     save_result_plt(data_idx, th1=0.4, th2=0.4, mc=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result_plt(177,th1=0.2, th2=0.4, mc=20) # good hyperparam... maybe! th1=0.4, th2=0.4, mc=50 \n",
    "# for data_idx in np.arange(0,400):\n",
    "#     save_result_plt(data_idx,th1=0.2, th2=0.4, mc=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_idx = 63, 74, 81, 96, 129, 155, 177, 328, 387, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "really less discriminative? : 327, 177, 169, 81, 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Does deviation map capture a less discriminative part?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'\n",
    "\n",
    "from os.path import join, expanduser\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from cam import CAM\n",
    "import util\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = CAM('vgg')\n",
    "\n",
    "class_dict = dataloader.get_class_dict(join(expanduser('~'),'data','imagenet'))[0]\n",
    "data_dict = map.valid_dataset.data_dict\n",
    "input_files = map.valid_dataset.img_files\n",
    "img_dir = map.valid_dataset.img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_plt(data_idxs, th1=0.2, th2=0.4, mc=30):\n",
    "    \n",
    "    # save the plot\n",
    "    fig, ax = plt.subplots(len(data_idxs),3,figsize=(12,4*len(data_idxs)))\n",
    "    \n",
    "    for idx, data_idx in enumerate(data_idxs):\n",
    "        # get true bbox\n",
    "        input_file = input_files[data_idx]\n",
    "        img_origin = Image.open(join(img_dir, input_file)).convert('RGB')\n",
    "        bboxes_true = data_dict[input_file][1]\n",
    "        bboxes_true = util.bboxes_resize(img_origin, bboxes_true, size=224)\n",
    "\n",
    "        # get input, target, and topk\n",
    "        input, target = map.get_item(data_idx)\n",
    "        target = target.cpu().item()\n",
    "\n",
    "        topk_idxs = map.topk(input)\n",
    "        top1_correct = target in topk_idxs[:1]\n",
    "        top5_correct = target in topk_idxs[:5]\n",
    "\n",
    "        att_idx = target\n",
    "\n",
    "        # origin\n",
    "        img, heatmap_origin, boolmap, boolmap_biggest, \\\n",
    "        bbox_pred = map.get_values(data_idx,att_idx, th1, phase='test')\n",
    "\n",
    "        # propose\n",
    "        _, heatmap_mean, heatmap_std, boolmap_propose, boolmap_biggest_propose, \\\n",
    "        bbox_propose = map.get_values(data_idx, att_idx, th1, th2, mc, phase='train')\n",
    "        heatmap_std_max = heatmap_std.max()\n",
    "\n",
    "        ax[idx,0].imshow(img)\n",
    "        for bbox_true in bboxes_true:\n",
    "            rect_true = patches.Rectangle((bbox_true[0],bbox_true[1]),bbox_true[2],bbox_true[3],\n",
    "                                          linewidth=3,edgecolor='#00d700',facecolor='none')\n",
    "            ax[idx,0].add_patch(rect_true)\n",
    "        if idx == 0:\n",
    "            ax[idx,0].set_title('input', fontsize=26, pad=15)\n",
    "        ax[idx,0].axis('off')\n",
    "\n",
    "        ax[idx,1].imshow(heatmap_origin, cmap='gray')\n",
    "        for bbox_true in bboxes_true:\n",
    "            rect_true = patches.Rectangle((bbox_true[0],bbox_true[1]),bbox_true[2],bbox_true[3],\n",
    "                                          linewidth=3,edgecolor='#00d700',facecolor='none')\n",
    "            ax[idx,1].add_patch(rect_true)        \n",
    "        if idx == 0:\n",
    "            ax[idx,1].set_title(r'$L^{grad}$', fontsize=26, pad=13)\n",
    "        ax[idx,1].axis('off')\n",
    "\n",
    "        ax[idx,2].imshow(heatmap_std, cmap='gray')\n",
    "        for bbox_true in bboxes_true:\n",
    "            rect_true = patches.Rectangle((bbox_true[0],bbox_true[1]),bbox_true[2],bbox_true[3],\n",
    "                                          linewidth=3,edgecolor='#00d700',facecolor='none')\n",
    "            ax[idx,2].add_patch(rect_true)\n",
    "        if idx == 0:\n",
    "            ax[idx,2].set_title(r'$L^{std}$', fontsize=25, pad=13)\n",
    "        ax[idx,2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "#     plt.show()\n",
    "    plt.savefig('z_multi.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result_plt([169, 81, 74])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct bboxes violinplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16, vgg16_bn\n",
    "\n",
    "import dataloader\n",
    "import util\n",
    "from cam import CAM\n",
    "\n",
    "import csv\n",
    "from os.path import join,expanduser\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1\n",
    "valid_loader = dataloader.imagenet_loader(bs=bs)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = CAM('vgg')\n",
    "data_dict = map.valid_dataset.data_dict\n",
    "input_files = map.valid_dataset.img_files\n",
    "img_dir = map.valid_dataset.img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes_dict(path):\n",
    "    bboxes_dict = {}\n",
    "    with open(path,'r') as cf:\n",
    "        for row in csv.reader(cf):\n",
    "            k,v = row\n",
    "            bboxes_dict[k] = eval(v)\n",
    "    return bboxes_dict\n",
    "\n",
    "bboxes_vgg_2 = get_bboxes_dict('runs/vgg/0.2/bbox.csv')\n",
    "bboxes_vgg_24 = get_bboxes_dict('runs/vgg/0.2_0.4/bbox.csv')\n",
    "bboxes_googlenet_2 = get_bboxes_dict('runs/googlenet/0.2/bbox.csv')\n",
    "bboxes_googlenet_24 = get_bboxes_dict('runs/googlenet/0.2_0.4/bbox.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_proposes(data_idx, bboxes_dict):\n",
    "    # get true bbox\n",
    "    input_file = input_files[data_idx]\n",
    "    img_origin = Image.open(join(img_dir, input_file)).convert('RGB')\n",
    "    bboxes_true = data_dict[input_file][1]\n",
    "    bboxes_true = util.bboxes_resize(img_origin, bboxes_true, size=224)\n",
    "\n",
    "    # get proposed bbox\n",
    "    bbox_propose = bboxes_dict[input_file]\n",
    "\n",
    "    # get iou\n",
    "    iou_propose = []\n",
    "    for bbox_true in bboxes_true:\n",
    "        iou_propose.append(util.get_iou(bbox_true, bbox_propose))\n",
    "    iou_max_bool = max(np.array(iou_propose) >= 0.5).astype(np.int)\n",
    "    iou_max_val = np.max(iou_propose)\n",
    "    \n",
    "    return iou_max_val if iou_max_bool == 1 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_proposes_vgg_2 = []\n",
    "iou_proposes_vgg_24 = []\n",
    "iou_proposes_googlenet_2 = []\n",
    "iou_proposes_googlenet_24 = []\n",
    "\n",
    "for data_idx, (inputs, targets) in tqdm_notebook(enumerate(valid_loader)):\n",
    "    val = get_iou_proposes(data_idx, bboxes_vgg_2)\n",
    "    if val is not None:\n",
    "        iou_proposes_vgg_2.append(val)\n",
    "    \n",
    "    val = get_iou_proposes(data_idx, bboxes_vgg_24)\n",
    "    if val is not None:\n",
    "        iou_proposes_vgg_24.append(val)\n",
    "    \n",
    "    val = get_iou_proposes(data_idx, bboxes_googlenet_2)\n",
    "    if val is not None:\n",
    "        iou_proposes_googlenet_2.append(val)\n",
    "    \n",
    "    val = get_iou_proposes(data_idx, bboxes_googlenet_24)\n",
    "    if val is not None:\n",
    "        iou_proposes_googlenet_24.append(val)\n",
    "    \n",
    "#     if data_idx == 3000:\n",
    "#         break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious = {'value': iou_proposes_vgg_2 + iou_proposes_vgg_24 + \n",
    "                 iou_proposes_googlenet_2 + iou_proposes_googlenet_24,\n",
    "        'method': ['GradCAM']*len(iou_proposes_vgg_2) + ['DropoutCAM']*len(iou_proposes_vgg_24) + \n",
    "                  ['GradCAM']*len(iou_proposes_googlenet_2) + ['DropoutCAM']*len(iou_proposes_googlenet_24),\n",
    "        'model': ['VGG']*(len(iou_proposes_vgg_2)+len(iou_proposes_vgg_24)) + \n",
    "                 ['GoogLeNet-Drop']*(len(iou_proposes_googlenet_2)+len(iou_proposes_googlenet_24))\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.violinplot(x='model', y='value', hue='method', data=df, split=True,\n",
    "               palette='Set2', scale='count', inner='quartile', cut=0, width=0.6)\n",
    "plt.legend(loc='upper center')\n",
    "plt.tight_layout()\n",
    "# plt.savefig('iou_comparison.png')\n",
    "# plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
