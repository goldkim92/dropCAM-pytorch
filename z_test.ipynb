{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.alexnet import Alexnet_for_CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Alexnet_for_CAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pretrainedmodels.model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pretrainedmodels.pretrained_settings['inceptionv3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'inceptionv4'\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import googlenet, vgg16, vgg19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = googlenet(pretrained=True)\n",
    "# model = vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- models that include dropout\n",
    "    - GoogleNet(InceptionV1), AlexNet, VGG19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg19, vgg16_bn\n",
    "\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = dataloader.imagenet_loader(bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16_bn(pretrained=True)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(epoch):\n",
    "    top1_accuracy = 0.\n",
    "    top5_accuracy = 0.\n",
    "    loss = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for idx, (inputs, targets) in tqdm_notebook(enumerate(valid_loader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss += criterion(outputs, targets).detach().cpu().item()\n",
    "\n",
    "        topk = outputs.topk(5,dim=1)[1]\n",
    "        top1_accuracy += topk[:,0].eq(targets).sum().cpu().item()\n",
    "        top5_accuracy += topk.eq(torch.stack([targets]*5,dim=1)).max(1)[0].sum().cpu().item()\n",
    "    \n",
    "    top1_accuracy /= len(valid_loader.dataset)\n",
    "    top5_accuracy /= len(valid_loader.dataset)\n",
    "    loss /= len(valid_loader.dataset)\n",
    "\n",
    "    print('Classification')\n",
    "    print(f'===> Test Loss: {loss:.4f}, Top1-Acc: {top1_accuracy*100:.4f}, Top5-Acc: {top5_accuracy*100:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy(0) \n",
    "# vgg19 ===> Test Loss: 0.0349, Top1-Acc: 72.3760, Top5-Acc: 90.8760\n",
    "# vgg16_bn ===> Test Loss: 0.0333, Top1-Acc: 73.3600, Top5-Acc: 91.5160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localization Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification & Localization (top-1 Loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg16, vgg16_bn\n",
    "\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from os.path import join,expanduser\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cam import CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = dataloader.imagenet_loader(bs=10)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = vgg16_bn(pretrained=True)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = CAM()\n",
    "data_dict = map.valid_dataset.data_dict\n",
    "input_files = map.valid_dataset.img_files\n",
    "img_dir = map.valid_dataset.img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_dict = {}\n",
    "with open('runs/vgg16bn/0.2/bbox.csv','r') as cf:\n",
    "    for row in csv.reader(cf):\n",
    "        k,v = row\n",
    "        bboxes_dict[k] = eval(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bboxes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### def test_accuracy(epoch):\n",
    "\n",
    "top1_acc_cls = 0.\n",
    "top5_acc_cls = 0.\n",
    "gtknown_acc_loc = 0.\n",
    "top1_acc_loc = 0.\n",
    "top5_acc_loc = 0.\n",
    "loss = 0.\n",
    "\n",
    "count = 0\n",
    "model.eval()\n",
    "for idx, (inputs, targets) in tqdm_notebook(enumerate(valid_loader)):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    loss += criterion(outputs, targets).detach().cpu().item()\n",
    "    \n",
    "    topk = outputs.topk(5,dim=1)[1]\n",
    "    top1_acc_clss = topk[:,0].eq(targets).cpu().numpy()\n",
    "    top5_acc_clss = topk.eq(torch.stack([targets]*5,dim=1)).max(1)[0].cpu().numpy()\n",
    "    \n",
    "    gtknown_acc_locs = []\n",
    "    for data_idx in range(idx*10,(idx+1)*10):\n",
    "        count += 1\n",
    "    \n",
    "        # get true bbox\n",
    "        input_file = input_files[data_idx]\n",
    "        img_origin = Image.open(join(img_dir, input_file)).convert('RGB')\n",
    "        bboxes_true = data_dict[input_file][1]\n",
    "        bboxes_true = util.bboxes_resize(img_origin, bboxes_true, size=224)\n",
    "\n",
    "        # get ours bbox\n",
    "        bbox_propose = bboxes_dict[input_file]\n",
    "\n",
    "        # get iou\n",
    "        iou_propose = []\n",
    "        for bbox_true in bboxes_true:\n",
    "            iou_propose.append(util.get_iou(bbox_true, bbox_propose))\n",
    "        iou_propose = max(np.array(iou_propose) >= 0.5).astype(np.int)\n",
    "        gtknown_acc_locs.append(iou_propose)\n",
    "        \n",
    "    top1_acc_locs = np.logical_and(top1_acc_clss, gtknown_acc_locs)\n",
    "    top5_acc_locs = np.logical_and(top5_acc_clss, gtknown_acc_locs)\n",
    "    \n",
    "    top1_acc_cls += top1_acc_clss.sum()\n",
    "    top5_acc_cls += top5_acc_clss.sum()\n",
    "    gtknown_acc_loc += np.array(gtknown_acc_locs).sum()\n",
    "    top1_acc_loc += top1_acc_locs.sum()\n",
    "    top5_acc_loc += top5_acc_locs.sum()\n",
    "    \n",
    "#     if idx == 999:\n",
    "#         break\n",
    "\n",
    "top1_acc_cls /= count\n",
    "top5_acc_cls /= count\n",
    "gtknown_acc_loc /= count\n",
    "top1_acc_loc /= count\n",
    "top5_acc_loc /= count\n",
    "print('Classification & Localization')\n",
    "print(f'===> Top1-Loc: {top1_acc_loc}, Top1-Acc: {top1_acc_cls}, GTKnown: {gtknown_acc_loc}')\n",
    "print(f'===> Top5-Loc: {top5_acc_loc}, Top5-Acc: {top5_acc_cls}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vgg16_bn \n",
    "vanilla ===> Top1-Loc: 0.44906, Top1-Acc: 0.7336, GTKnown: 0.57684, Top5-Loc: 0.54378, Top5-Acc: 0.91516 <br>\n",
    "ours ===> Top1-Loc: 0.47832, Top1-Acc: 0.7336, GTKnown: 0.61506, Top5-Loc: 0.5803, Top5-Acc: 0.91516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join('aa','bb','','cc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2'\n",
    "\n",
    "from os.path import join\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from cam import CAM\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = CAM()\n",
    "\n",
    "class_dict = dataloader.get_class_dict('/data2/imagenet')[0]\n",
    "data_dict = map.valid_dataset.data_dict\n",
    "input_files = map.valid_dataset.img_files\n",
    "img_dir = map.valid_dataset.img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result_plt(data_idx, th1=0.2, th2=10, mc=15):\n",
    "    # get true bbox\n",
    "    input_file = input_files[data_idx]\n",
    "    img_origin = Image.open(join(img_dir, input_file)).convert('RGB')\n",
    "    bboxes_true = data_dict[input_file][1]\n",
    "    bboxes_true = util.bboxes_resize(img_origin, bboxes_true, size=224)\n",
    "    \n",
    "    # get input, target, and topk\n",
    "    input, target = map.get_item(data_idx)\n",
    "    target = target.cpu().item()\n",
    "\n",
    "    topk_idxs = map.topk(input)\n",
    "    top1_correct = target in topk_idxs[:1]\n",
    "    top5_correct = target in topk_idxs[:5]\n",
    "    \n",
    "    att_idx = target\n",
    "    \n",
    "    # origin\n",
    "    img, heatmap_origin, boolmap, boolmap_biggest, \\\n",
    "    bbox_pred = map.get_values(data_idx,att_idx, th1=0.2, phase='test')\n",
    "    \n",
    "    # propose\n",
    "    _, heatmap_mean, heatmap_std, boolmap_propose, boolmap_biggest_propose, \\\n",
    "    bbox_propose = map.get_values(data_idx, att_idx, th1, th2, mc, phase='train')\n",
    "    heatmap_std_max = heatmap_std.max()\n",
    "    \n",
    "    # save the plot\n",
    "    fig, ax = plt.subplots(2,6,figsize=(21,7))\n",
    "\n",
    "    ax[0,0].imshow(img)\n",
    "    ax[0,0].set_title('origin')\n",
    "    ax[0,0].axis('off')\n",
    "\n",
    "    ax[0,1].imshow(heatmap_origin)\n",
    "    ax[0,1].set_title('heatmap')\n",
    "    ax[0,1].axis('off')\n",
    "\n",
    "    ax[0,2].imshow(img)\n",
    "    ax[0,2].imshow(heatmap_origin, alpha=0.5, cmap='jet')\n",
    "    ax[0,2].set_title(f'CAM \"{class_dict[target]}\"\\n Top-1: {top1_correct}, Top-5: {top5_correct}')\n",
    "    ax[0,2].axis('off')\n",
    "\n",
    "    ax[0,3].imshow(Image.fromarray((boolmap*255).astype(np.uint8)), cmap='gray')\n",
    "    ax[0,3].set_title('boolean map')\n",
    "    ax[0,3].axis('off')\n",
    "\n",
    "    ax[0,4].imshow(Image.fromarray((boolmap_biggest*255).astype(np.uint8)), cmap='gray')\n",
    "    ax[0,4].set_title('biggest boolean map')\n",
    "    ax[0,4].axis('off')\n",
    "\n",
    "    ax[0,5].imshow(img)\n",
    "    for bbox_true in bboxes_true:\n",
    "        rect_true = patches.Rectangle((bbox_true[0],bbox_true[1]),bbox_true[2],bbox_true[3],\n",
    "                                      linewidth=2,edgecolor='g',facecolor='none')\n",
    "        ax[0,5].add_patch(rect_true)\n",
    "    rect_pred = patches.Rectangle((bbox_pred[0],bbox_pred[1]),bbox_pred[2],bbox_pred[3],\n",
    "                                  linewidth=2,edgecolor='r',facecolor='none')\n",
    "    ax[0,5].add_patch(rect_pred)\n",
    "    ax[0,5].set_title('bounding box')\n",
    "    ax[0,5].axis('off')\n",
    "\n",
    "\n",
    "    ax[1,0].imshow(heatmap_mean, cmap='gray')\n",
    "    ax[1,0].set_title('heatmap_mean')\n",
    "    ax[1,0].axis('off')\n",
    "\n",
    "    ax[1,1].imshow(heatmap_std, cmap='gray')\n",
    "    ax[1,1].set_title(f'heatmap_std\\n max value: {heatmap_std_max:.01f}')\n",
    "    ax[1,1].axis('off')\n",
    "\n",
    "    im1 = ax[1,2].imshow(heatmap_mean, cmap='Reds', label='mean')\n",
    "    im2 = ax[1,2].imshow(heatmap_std, cmap='Blues', label='std', alpha=0.5)\n",
    "    ax[1,2].set_title('overlap')\n",
    "    ax[1,2].axis('off')\n",
    "    patch = [patches.Patch(color=im1.cmap(150), label='mean'), \n",
    "             patches.Patch(color=im2.cmap(150), label='std')]\n",
    "    ax[1,2].legend(handles=patch, loc='best')\n",
    "\n",
    "    ax[1,3].imshow(Image.fromarray((boolmap_propose*255).astype(np.uint8)), cmap='gray')\n",
    "    ax[1,3].set_title('boolean map')\n",
    "    ax[1,3].axis('off')\n",
    "\n",
    "    ax[1,4].imshow(Image.fromarray((boolmap_biggest_propose*255).astype(np.uint8)), cmap='gray')\n",
    "    ax[1,4].set_title('biggest boolean map')\n",
    "    ax[1,4].axis('off')\n",
    "\n",
    "    ax[1,5].imshow(img)\n",
    "    for bbox_true in bboxes_true:\n",
    "        rect_true = patches.Rectangle((bbox_true[0],bbox_true[1]),bbox_true[2],bbox_true[3],\n",
    "                                      linewidth=2,edgecolor='g',facecolor='none')\n",
    "        ax[1,5].add_patch(rect_true)\n",
    "    rect_pred = patches.Rectangle((bbox_propose[0],bbox_propose[1]),bbox_propose[2],bbox_propose[3],\n",
    "                                  linewidth=2,edgecolor='r',facecolor='none')\n",
    "    ax[1,5].add_patch(rect_pred)\n",
    "    ax[1,5].set_title('bounding box')\n",
    "    ax[1,5].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "#     plt.savefig(join('save',f'{data_idx:05d}.png'))\n",
    "#     plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data_idx in tqdm_notebook(range(1000)):\n",
    "#     save_result_plt(data_idx, th1=0.4, th2=0.4, mc=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_result_plt(129,th1=0.4, th2=0.4, mc=50) # good hyperparam... maybe! th1=0.4, th2=0.4, mc=50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
